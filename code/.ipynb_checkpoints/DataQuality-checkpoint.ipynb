{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78226c88-0329-47cb-a216-07b1127ec585",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.618s\n",
      "\n",
      "OK\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.628s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import yaml\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "class TestCharStats(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        # Loading configuration from config.yaml\n",
    "        with open(\"config.yaml\", \"r\") as config_file:\n",
    "            config = yaml.safe_load(config_file)\n",
    "            \n",
    "        # Create a Spark session with a custom configuration\n",
    "        self.spark = SparkSession.builder \\\n",
    "            .appName(\"TestCharStats\") \\\n",
    "            .getOrCreate()\n",
    "        # Set the log level to ERROR or FATAL\n",
    "        self.spark.sparkContext.setLogLevel(\"ERROR\")  # You can change \"ERROR\" to \"FATAL\" if needed\n",
    "        \n",
    "        # Assign configuration variables\n",
    "        self.table_name = config[\"table_name\"]\n",
    "        self.primary_key_columns = config[\"primary_key_columns\"]\n",
    "        self.threshold_percentage = config[\"threshold_percentage\"]\n",
    "        self.output_path = config[\"output_path\"]\n",
    "        self.absolute_table_name =f\"{self.output_path}/{self.table_name}\"\n",
    "\n",
    "    def tearDown(self):\n",
    "        # Stop the Spark session\n",
    "        self.spark.stop()\n",
    "\n",
    "    def log_test_result(self, test_name, status, reason=\"\"):\n",
    "        timestamp = datetime.datetime.now()\n",
    "        # Creating a dictionary for the test result\n",
    "        result = {\n",
    "            \"Table Name\": self.table_name,\n",
    "            \"Test Name\": test_name,\n",
    "            \"Status\": status,\n",
    "            \"Reason\": reason,\n",
    "            \"Timestamp\": timestamp\n",
    "        }\n",
    "        # Append the result to the test_results list\n",
    "        test_results.append(result)\n",
    "\n",
    "    def test_primary_key(self):\n",
    "        # Loading the current data\n",
    "        df = self.spark.read.parquet(self.absolute_table_name)  \n",
    "\n",
    "        # Checking primary key columns to make sure no duplicates\n",
    "        num_rows = df.count()\n",
    "        num_distinct_rows = df.select(*self.primary_key_columns).distinct().count()\n",
    "        #self.assertEqual(num_rows, num_distinct_rows)\n",
    "        if num_rows == num_distinct_rows:\n",
    "            self.log_test_result(\"test_primary_key\", \"PASS\")\n",
    "        else:\n",
    "            count_duplicate_key = num_rows - num_distinct_rows\n",
    "            self.log_test_result(\"test_primary_key\", \"FAIL\", f\"total of {count_duplicate_key} Duplicate primary key values found.\")\n",
    "\n",
    "    def test_count_increase(self):\n",
    "        # Loading the today's and previous day data for the comparision of countyour DataFrames for previous and current loads\n",
    "        df_previous = self.spark.read.parquet(self.absolute_table_name)\n",
    "        df_current = self.spark.read.parquet(self.absolute_table_name)\n",
    "\n",
    "        # Calculating the count of increased percentage\n",
    "        count_previous = df_previous.count()\n",
    "        count_current = df_current.count()\n",
    "        increase_percentage = (count_current - count_previous) / count_previous * 100\n",
    "\n",
    "        if increase_percentage >= self.threshold_percentage:\n",
    "            self.log_test_result(\"test_count_increase\", \"FAIL\", f\"Count_increase percentage is more than threshold\")\n",
    "        else:\n",
    "            self.log_test_result(\"test_count_increase\", \"PASS\", \"Count_increase percentage is below threshold\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Creating an empty list to store test results\n",
    "    test_results = []\n",
    "\n",
    "    # Creating a test suite\n",
    "    test_suite = unittest.TestLoader().loadTestsFromTestCase(TestCharStats)\n",
    "\n",
    "    # Running the tests\n",
    "    test_runner = unittest.TextTestRunner()\n",
    "\n",
    "    # Run each test and log the results\n",
    "    for test_case in test_suite:\n",
    "        test_result = test_runner.run(test_case)\n",
    "\n",
    "    # Converting the test results to write into a file\n",
    "    results_df = pd.DataFrame(test_results)\n",
    "    \n",
    "\n",
    "    # Write the results to a CSV file\n",
    "    results_df.to_csv(\"test_results.csv\", index=False)\n",
    "    results_df.head()\n",
    "    # Create a summary DataFrame to store load status\n",
    "    load_status_df = results_df.groupby([\"Table Name\"])[\"Status\"].max().reset_index()\n",
    "    load_status_df.loc[:, \"Test Type\"] = \"Data Quality Checks\"\n",
    "    \n",
    "    # Check if any row in the test results DataFrame has \"Failed\" in the \"Status\" column\n",
    "    if \"FAILED\" in load_status_df[\"Status\"].str.upper().values:\n",
    "        # Set the status in the summary DataFrame to \"Failed\"\n",
    "        load_status_df.loc[:, \"Status\"] = \"FAIL\"\n",
    "    else:\n",
    "        load_status_df.loc[:, \"Status\"] = \"PASS\"\n",
    "    \n",
    "    # Add a Date column with the current date and time\n",
    "    load_status_df[\"Date\"] = pd.to_datetime('today').date()\n",
    "    \n",
    "    # Display the summary load status\n",
    "    load_status_df.to_csv(\"load_status.csv\", index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90881d7-f054-4ebd-ae3f-5cbc1c5928cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2976b8d-ae01-4ba9-a0a9-862d33984d18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
