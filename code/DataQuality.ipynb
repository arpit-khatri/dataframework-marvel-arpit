{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c90881d7-f054-4ebd-ae3f-5cbc1c5928cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.427s\n",
      "\n",
      "OK\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.123s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------+------+--------------------+--------------------+\n",
      "|        Table Name|          Test Type|Status|              Reason|                Date|\n",
      "+------------------+-------------------+------+--------------------+--------------------+\n",
      "|char_stats_day_dly|test_count_increase|  PASS|Count_increase pe...|2023-09-17 06:04:...|\n",
      "|char_stats_day_dly|   test_primary_key|  FAIL|total of 1 Duplic...|2023-09-17 06:04:...|\n",
      "+------------------+-------------------+------+--------------------+--------------------+\n",
      "\n",
      "load_status.csv\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import yaml\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, upper\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "class TestCharStats(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        # Loading configuration from config.yaml\n",
    "        with open(\"config.yaml\", \"r\") as config_file:\n",
    "            config = yaml.safe_load(config_file)\n",
    "            \n",
    "        # Create a Spark session with a custom configuration\n",
    "        self.spark = SparkSession.builder \\\n",
    "            .appName(\"TestCharStats\") \\\n",
    "            .getOrCreate()\n",
    "        # Set the log level to ERROR or FATAL\n",
    "        self.spark.sparkContext.setLogLevel(\"ERROR\")  # You can change \"ERROR\" to \"FATAL\" if needed\n",
    "        \n",
    "        # Assign configuration variables\n",
    "        self.table_name = config[\"table_name\"]\n",
    "        self.primary_key_columns = config[\"primary_key_columns\"]\n",
    "        self.threshold_percentage = config[\"threshold_percentage\"]\n",
    "        self.output_path = config[\"output_path\"]\n",
    "        self.absolute_table_name =f\"{self.output_path}/{self.table_name}\"\n",
    "\n",
    "    def tearDown(self):\n",
    "        # Stop the Spark session\n",
    "        self.spark.stop()\n",
    "\n",
    "    def log_test_result(self, test_name, status, reason=\"\"):\n",
    "        timestamp = datetime.datetime.now()\n",
    "        # Creating a dictionary for the test result\n",
    "        result = {\n",
    "            \"Table Name\": self.table_name,\n",
    "            \"Test Name\": test_name,\n",
    "            \"Status\": status,\n",
    "            \"Reason\": reason,\n",
    "            \"Timestamp\": timestamp\n",
    "        }\n",
    "        # Append the result to the test_results list\n",
    "        test_results.append(result)\n",
    "\n",
    "    def test_primary_key(self):\n",
    "        # Loading the current data\n",
    "        df = self.spark.read.parquet(self.absolute_table_name)  \n",
    "\n",
    "        # Checking primary key columns to make sure no duplicates\n",
    "        num_rows = df.count()\n",
    "        num_distinct_rows = df.select(*self.primary_key_columns).distinct().count()\n",
    "        if num_rows == num_distinct_rows:\n",
    "            self.log_test_result(\"test_primary_key\", \"PASS\")\n",
    "        else:\n",
    "            count_duplicate_key = num_rows - num_distinct_rows\n",
    "            self.log_test_result(\"test_primary_key\", \"FAIL\", f\"total of {count_duplicate_key} Duplicate primary key values found.\")\n",
    "\n",
    "    def test_count_increase(self):\n",
    "        # Loading the today's and previous day data for the comparision of countyour DataFrames for previous and current loads\n",
    "        df_previous = self.spark.read.parquet(self.absolute_table_name)\n",
    "        df_current = self.spark.read.parquet(self.absolute_table_name)\n",
    "\n",
    "        # Calculating the count of increased percentage\n",
    "        count_previous = df_previous.count()\n",
    "        count_current = df_current.count()\n",
    "        increase_percentage = (count_current - count_previous) / count_previous * 100\n",
    "\n",
    "        if increase_percentage >= self.threshold_percentage:\n",
    "            self.log_test_result(\"test_count_increase\", \"FAIL\", f\"Count_increase percentage is more than threshold\")\n",
    "        else:\n",
    "            self.log_test_result(\"test_count_increase\", \"PASS\", \"Count_increase percentage is below threshold\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Creating an empty list to store test results\n",
    "    test_results = []\n",
    "\n",
    "    # Creating a test suite\n",
    "    test_suite = unittest.TestLoader().loadTestsFromTestCase(TestCharStats)\n",
    "\n",
    "    # Running the tests\n",
    "    test_runner = unittest.TextTestRunner()\n",
    "\n",
    "    # Run each test and log the results\n",
    "    for test_case in test_suite:\n",
    "        test_result = test_runner.run(test_case)\n",
    "        \n",
    "   # Create a Spark session\n",
    "    spark = SparkSession.builder.appName(\"DataQuality\").getOrCreate()\n",
    "    \n",
    "    schema = [\"Table Name\", \"Test Type\", \"Status\", \"Reason\", \"Date\"]\n",
    "    # Converting the test results to spark dataframe\n",
    "    results_df = pd.DataFrame(test_results)\n",
    "    results_df.to_csv(\"DataQuality.csv\", index=False)\n",
    "    # Write the individual Data Quality results to a CSV file\n",
    "    data_quality_df = spark.createDataFrame(results_df, schema=schema) \n",
    "    data_quality_df.show()\n",
    "    \n",
    "     # Create a summary DataFrame to store load status\n",
    "    #load_status_df = data_quality_df.groupby(\"Table Name\")\\\n",
    "     #   .agg(F.max(\"Status\").alias(\"Status\"), F.lit(\"Data Quality Checks\").alias(\"Test Type\"), F.date_sub(F.current_date(), 1).alias(\"Date\"))\n",
    "    load_status_df = data_quality_df.groupby(\"Table Name\")\\\n",
    "        .agg(F.max(\"Status\").alias(\"Status\"), F.lit(\"Data Quality Checks\").alias(\"Test Type\"), F.current_date().alias(\"Date\"))\n",
    "\n",
    "\n",
    "    # Check if any row in the test results DataFrame has \"FAIL\" in the \"Status\" column\n",
    "    if \"FAIL\" in load_status_df.select(\"Status\").distinct().rdd.map(lambda x: x[0].upper()).collect():\n",
    "        # Set the status in the summary DataFrame to \"FAIL\"\n",
    "        load_status_df = load_status_df.withColumn(\"Status\", F.lit(\"FAIL\"))\n",
    "\n",
    "    # Define the file path for the load status CSV\n",
    "    csv_file_path = \"load_status\"\n",
    "    \n",
    "    # Check if the file already exists\n",
    "    #if os.path.isfile(f\"work/digital/logs/{csv_file_path}.csv\"):\n",
    "    if os.path.isfile(f\"{csv_file_path}.csv\"):\n",
    "        print(f\"{csv_file_path}.csv\")\n",
    "        ## Read the existing load status CSV directly\n",
    "        existing_load_status_df = spark.read.csv(f\"{csv_file_path}.csv\", header=True, inferSchema=True)\n",
    "        final_load_status_df = existing_load_status_df.union(load_status_df).distinct()\n",
    "        final_load_status_dfp=final_load_status_df.toPandas()\n",
    "        final_load_status_dfp.to_csv(\"load_status.csv\",index=False)\n",
    "    else:\n",
    "        # The file doesn't exist, create it with the current load status\n",
    "        final_load_status_df = load_status_df\n",
    "        final_load_status_dfp=final_load_status_df.toPandas()\n",
    "        final_load_status_dfp.to_csv(\"load_status.csv\", mode='a', index=False, header=not os.path.exists(\"load_status.csv\"))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed12c22a-134f-4493-ac9e-c8bc07b2ed58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " printing absolute name :/home/jovyan/work/digital/target/char_stats_day_dly\n",
      " printing absolute name :/home/jovyan/work/digital/target/char_stats_day_dly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 4.659s\n",
      "\n",
      "OK\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.697s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " printing absolute name :/home/jovyan/work/digital/target/char_stats_day_dly\n",
      "+------------------+-------------------+------+--------------------+--------------------+\n",
      "|        Table Name|          Test Type|Status|              Reason|                Date|\n",
      "+------------------+-------------------+------+--------------------+--------------------+\n",
      "|char_stats_day_dly|test_count_increase|  PASS|Count_increase pe...|2023-09-17 07:58:...|\n",
      "|char_stats_day_dly|   test_primary_key|  FAIL|total of 1 Duplic...|2023-09-17 07:58:...|\n",
      "+------------------+-------------------+------+--------------------+--------------------+\n",
      "\n",
      "Data Quality Job completed successfully\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import yaml\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, upper\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "class TestCharStats(unittest.TestCase):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # Loading configuration from config.yaml\n",
    "        with open(\"config.yaml\", \"r\") as config_file:\n",
    "            config = yaml.safe_load(config_file)\n",
    "\n",
    "        # Create a Spark session\n",
    "        self.spark = SparkSession.builder.appName(\"TestCharStats\").getOrCreate()\n",
    "\n",
    "        # Set the log level to ERROR or FATAL\n",
    "        self.spark.sparkContext.setLogLevel(\"ERROR\")  # You can change \"ERROR\" to \"FATAL\" if needed\n",
    "\n",
    "        # Assign configuration variables\n",
    "        self.table_name = config[\"table_name\"]\n",
    "        self.primary_key_columns = config[\"primary_key_columns\"]\n",
    "        self.threshold_percentage = config[\"threshold_percentage\"]\n",
    "        self.output_path = config[\"output_path\"]\n",
    "        self.log_path = config[\"log_path\"]\n",
    "        self.absolute_table_name =f\"{self.output_path}/{self.table_name}\"\n",
    "\n",
    "        print(f\" printing absolute name :{self.absolute_table_name}\")\n",
    "        \n",
    "    def log_test_result(self, test_name, status, reason=\"\"):\n",
    "        timestamp = datetime.datetime.now()\n",
    "        # Creating a dictionary for the test result\n",
    "        result = {\n",
    "            \"Table Name\": self.table_name,\n",
    "            \"Test Name\": test_name,\n",
    "            \"Status\": status,\n",
    "            \"Reason\": reason,\n",
    "            \"Timestamp\": timestamp\n",
    "        }\n",
    "        # Append the result to the test_results list\n",
    "        test_results.append(result)\n",
    "\n",
    "    def test_primary_key(self):\n",
    "        # Loading the current data\n",
    "        df = self.spark.read.parquet(self.absolute_table_name)  \n",
    "\n",
    "        # Checking primary key columns to make sure no duplicates\n",
    "        num_rows = df.count()\n",
    "        num_distinct_rows = df.select(*self.primary_key_columns).distinct().count()\n",
    "        if num_rows == num_distinct_rows:\n",
    "            self.log_test_result(\"test_primary_key\", \"PASS\")\n",
    "        else:\n",
    "            count_duplicate_key = num_rows - num_distinct_rows\n",
    "            self.log_test_result(\"test_primary_key\", \"FAIL\", f\"total of {count_duplicate_key} Duplicate primary key values found.\")\n",
    "\n",
    "    def test_count_increase(self):\n",
    "        # Loading the today's and previous day data for the comparision of countyour DataFrames for previous and current loads\n",
    "        df_previous = self.spark.read.parquet(self.absolute_table_name)\n",
    "        df_current = self.spark.read.parquet(self.absolute_table_name)\n",
    "\n",
    "        # Calculating the count of increased percentage\n",
    "        count_previous = df_previous.count()\n",
    "        count_current = df_current.count()\n",
    "        increase_percentage = (count_current - count_previous) / count_previous * 100\n",
    "\n",
    "        if increase_percentage >= self.threshold_percentage:\n",
    "            self.log_test_result(\"test_count_increase\", \"FAIL\", f\"Count_increase percentage is more than threshold\")\n",
    "        else:\n",
    "            self.log_test_result(\"test_count_increase\", \"PASS\", \"Count_increase percentage is below threshold\")\n",
    "            \n",
    "    def daily_log_status(self, results_df):\n",
    "        # Write the individual Data Quality results to a CSV file\n",
    "        results_df.to_csv(f\"{self.log_path}/DataQuality.csv\", index=False)\n",
    "        spark = SparkSession.builder.appName(\"DataQuality\").getOrCreate()\n",
    "        schema = [\"Table Name\", \"Test Type\", \"Status\", \"Reason\", \"Date\"]    \n",
    "        data_quality_df = spark.createDataFrame(results_df, schema=schema) \n",
    "        data_quality_df.show()\n",
    "\n",
    "        # Creating a summary DataFrame to store load status\n",
    "        load_status_df = data_quality_df.groupby(\"Table Name\") \\\n",
    "            .agg(F.max(\"Status\").alias(\"Status\"), F.lit(\"DataQuality\").alias(\"Test Type\"), F.current_date().alias(\"Date\"))\n",
    "\n",
    "        # Checking if any row in the test results DataFrame has \"FAIL\" in the \"Status\" column\n",
    "        if \"FAIL\" in load_status_df.select(\"Status\").distinct().rdd.map(lambda x: x[0].upper()).collect():\n",
    "            # Set the status in the summary DataFrame to \"FAIL\"\n",
    "            load_status_df = load_status_df.withColumn(\"Status\", F.lit(\"FAIL\"))\n",
    "\n",
    "        # Define the file path for the load status CSV\n",
    "        csv_file_path = \"load_status\"\n",
    "\n",
    "        # Check if the log file already exists\n",
    "        if os.path.isfile(f\"{self.log_path}/{csv_file_path}.csv\"):\n",
    "            # Reading the existing load status CSV directly\n",
    "            existing_load_status_df = spark.read.csv(f\"{self.log_path}/{csv_file_path}.csv\", header=True, inferSchema=True)\n",
    "            final_load_status_df = existing_load_status_df.union(load_status_df).distinct()\n",
    "            final_load_status_dfp = final_load_status_df.toPandas()\n",
    "            final_load_status_dfp.to_csv(f\"{self.log_path}/load_status.csv\", index=False)\n",
    "        else:\n",
    "            # if the file doesn't exist, creating it with the current load status\n",
    "            final_load_status_df = load_status_df\n",
    "            final_load_status_dfp = final_load_status_df.toPandas()\n",
    "            final_load_status_dfp.to_csv(f\"{self.log_path}/load_status.csv\", mode='a', index=False, header=not os.path.exists(f\"{self.log_path}/load_status.csv\"))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Creating an empty list to store test results\n",
    "    test_results = []\n",
    "\n",
    "    # Creating a test suite\n",
    "    test_suite = unittest.TestLoader().loadTestsFromTestCase(TestCharStats)\n",
    "\n",
    "    # Running the tests\n",
    "    test_runner = unittest.TextTestRunner()\n",
    "\n",
    "    # Run each test and log the results\n",
    "    for test_case in test_suite:\n",
    "        test_result = test_runner.run(test_case)\n",
    "        \n",
    "     # Converting the test results to write into a file\n",
    "    results_df = pd.DataFrame(test_results)\n",
    "\n",
    "    # Call the daily_log_status function with test_results as an argument\n",
    "    test_instance = TestCharStats()\n",
    "    test_instance.daily_log_status(results_df)\n",
    "    print(\"Data Quality Job completed successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f88805-d992-4755-9c02-13db8a1309a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
