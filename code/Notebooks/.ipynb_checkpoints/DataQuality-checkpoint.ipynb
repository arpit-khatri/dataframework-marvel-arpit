{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c90881d7-f054-4ebd-ae3f-5cbc1c5928cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E\n",
      "======================================================================\n",
      "ERROR: test_count_increase (__main__.TestCharStats.test_count_increase)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29081/1246249920.py\", line 64, in test_count_increase\n",
      "    df_previous = self.spark.read.parquet(self.absolute_table_name)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/pyspark/sql/readwriter.py\", line 531, in parquet\n",
      "    return self._df(self._jreader.parquet(_to_seq(self._spark._sc, paths)))\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1322, in __call__\n",
      "    return_value = get_return_value(\n",
      "                   ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/pyspark/errors/exceptions/captured.py\", line 175, in deco\n",
      "    raise converted from None\n",
      "pyspark.errors.exceptions.captured.AnalysisException: [PATH_NOT_FOUND] Path does not exist: file:/home/jovyan/work/digital/monitoring/char_stats_day_dly.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.088s\n",
      "\n",
      "FAILED (errors=1)\n",
      "E\n",
      "======================================================================\n",
      "ERROR: test_primary_key (__main__.TestCharStats.test_primary_key)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29081/1246249920.py\", line 51, in test_primary_key\n",
      "    df = self.spark.read.parquet(self.absolute_table_name)\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/pyspark/sql/readwriter.py\", line 531, in parquet\n",
      "    return self._df(self._jreader.parquet(_to_seq(self._spark._sc, paths)))\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1322, in __call__\n",
      "    return_value = get_return_value(\n",
      "                   ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/pyspark/errors/exceptions/captured.py\", line 175, in deco\n",
      "    raise converted from None\n",
      "pyspark.errors.exceptions.captured.AnalysisException: [PATH_NOT_FOUND] Path does not exist: file:/home/jovyan/work/digital/monitoring/char_stats_day_dly.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.733s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 99\u001b[0m\n\u001b[1;32m     97\u001b[0m results_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataQuality.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Write the individual Data Quality results to a CSV file\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m data_quality_df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreateDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m    100\u001b[0m data_quality_df\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m    102\u001b[0m  \u001b[38;5;66;03m# Create a summary DataFrame to store load status\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m#load_status_df = data_quality_df.groupby(\"Table Name\")\\\u001b[39;00m\n\u001b[1;32m    104\u001b[0m  \u001b[38;5;66;03m#   .agg(F.max(\"Status\").alias(\"Status\"), F.lit(\"Data Quality Checks\").alias(\"Test Type\"), F.date_sub(F.current_date(), 1).alias(\"Date\"))\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py:1273\u001b[0m, in \u001b[0;36mSparkSession.createDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m   1269\u001b[0m     data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data, columns\u001b[38;5;241m=\u001b[39mcolumn_names)\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_pandas \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[1;32m   1272\u001b[0m     \u001b[38;5;66;03m# Create a DataFrame from pandas DataFrame.\u001b[39;00m\n\u001b[0;32m-> 1273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSparkSession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreateDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplingRatio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverifySchema\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_dataframe(\n\u001b[1;32m   1277\u001b[0m     data, schema, samplingRatio, verifySchema  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1278\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/pandas/conversion.py:439\u001b[0m, in \u001b[0;36mSparkConversionMixin.createDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    437\u001b[0m             warn(msg)\n\u001b[1;32m    438\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m--> 439\u001b[0m converted_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_from_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimezone\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_dataframe(converted_data, schema, samplingRatio, verifySchema)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/pandas/conversion.py:503\u001b[0m, in \u001b[0;36mSparkConversionMixin._convert_from_pandas\u001b[0;34m(self, pdf, schema, timezone)\u001b[0m\n\u001b[1;32m    498\u001b[0m             pdf[column] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(\n\u001b[1;32m    499\u001b[0m                 ser\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mto_pytimedelta(), index\u001b[38;5;241m=\u001b[39mser\u001b[38;5;241m.\u001b[39mindex, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39mser\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    500\u001b[0m             )\n\u001b[1;32m    502\u001b[0m \u001b[38;5;66;03m# Convert pandas.DataFrame to list of numpy records\u001b[39;00m\n\u001b[0;32m--> 503\u001b[0m np_records \u001b[38;5;241m=\u001b[39m \u001b[43mpdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;66;03m# Check if any columns need to be fixed for Spark to infer properly\u001b[39;00m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np_records) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:2551\u001b[0m, in \u001b[0;36mDataFrame.to_records\u001b[0;34m(self, index, column_dtypes, index_dtypes)\u001b[0m\n\u001b[1;32m   2548\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype_mapping\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m specified for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2549\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m-> 2551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromarrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnames\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mformats\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mformats\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/numpy/core/records.py:643\u001b[0m, in \u001b[0;36mfromarrays\u001b[0;34m(arrayList, dtype, shape, formats, names, titles, aligned, byteorder)\u001b[0m\n\u001b[1;32m    640\u001b[0m shape \u001b[38;5;241m=\u001b[39m _deprecate_shape_0_as_None(shape)\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 643\u001b[0m     shape \u001b[38;5;241m=\u001b[39m \u001b[43marrayList\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(shape, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    645\u001b[0m     shape \u001b[38;5;241m=\u001b[39m (shape,)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import yaml\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, upper\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "class TestCharStats(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        # Loading configuration from config.yaml\n",
    "        with open(\"config.yaml\", \"r\") as config_file:\n",
    "            config = yaml.safe_load(config_file)\n",
    "            \n",
    "        # Create a Spark session with a custom configuration\n",
    "        self.spark = SparkSession.builder \\\n",
    "            .appName(\"TestCharStats\") \\\n",
    "            .getOrCreate()\n",
    "        # Set the log level to ERROR or FATAL\n",
    "        self.spark.sparkContext.setLogLevel(\"ERROR\")  # You can change \"ERROR\" to \"FATAL\" if needed\n",
    "        \n",
    "        # Assign configuration variables\n",
    "        self.table_name = config[\"table_name\"]\n",
    "        self.primary_key_columns = config[\"primary_key_columns\"]\n",
    "        self.threshold_percentage = config[\"threshold_percentage\"]\n",
    "        self.output_path = config[\"monitoring_path\"]\n",
    "        self.absolute_table_name =f\"{self.output_path}/{self.table_name}\"\n",
    "\n",
    "    def tearDown(self):\n",
    "        # Stop the Spark session\n",
    "        self.spark.stop()\n",
    "\n",
    "    def log_test_result(self, test_name, status, reason=\"\"):\n",
    "        timestamp = datetime.datetime.now()\n",
    "        # Creating a dictionary for the test result\n",
    "        result = {\n",
    "            \"Table Name\": self.table_name,\n",
    "            \"Test Name\": test_name,\n",
    "            \"Status\": status,\n",
    "            \"Reason\": reason,\n",
    "            \"Timestamp\": timestamp\n",
    "        }\n",
    "        # Append the result to the test_results list\n",
    "        test_results.append(result)\n",
    "\n",
    "    def test_primary_key(self):\n",
    "        # Loading the current data\n",
    "        df = self.spark.read.parquet(self.absolute_table_name)  \n",
    "\n",
    "        # Checking primary key columns to make sure no duplicates\n",
    "        num_rows = df.count()\n",
    "        num_distinct_rows = df.select(*self.primary_key_columns).distinct().count()\n",
    "        if num_rows == num_distinct_rows:\n",
    "            self.log_test_result(\"test_primary_key\", \"PASS\")\n",
    "        else:\n",
    "            count_duplicate_key = num_rows - num_distinct_rows\n",
    "            self.log_test_result(\"test_primary_key\", \"FAIL\", f\"total of {count_duplicate_key} Duplicate primary key values found.\")\n",
    "\n",
    "    def test_count_increase(self):\n",
    "        # Loading the today's and previous day data for the comparision of countyour DataFrames for previous and current loads\n",
    "        df_previous = self.spark.read.parquet(self.absolute_table_name)\n",
    "        df_current = self.spark.read.parquet(self.absolute_table_name)\n",
    "\n",
    "        # Calculating the count of increased percentage\n",
    "        count_previous = df_previous.count()\n",
    "        count_current = df_current.count()\n",
    "        increase_percentage = (count_current - count_previous) / count_previous * 100\n",
    "\n",
    "        if increase_percentage >= self.threshold_percentage:\n",
    "            self.log_test_result(\"test_count_increase\", \"FAIL\", f\"Count_increase percentage is more than threshold\")\n",
    "        else:\n",
    "            self.log_test_result(\"test_count_increase\", \"PASS\", \"Count_increase percentage is below threshold\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Creating an empty list to store test results\n",
    "    test_results = []\n",
    "\n",
    "    # Creating a test suite\n",
    "    test_suite = unittest.TestLoader().loadTestsFromTestCase(TestCharStats)\n",
    "\n",
    "    # Running the tests\n",
    "    test_runner = unittest.TextTestRunner()\n",
    "\n",
    "    # Run each test and log the results\n",
    "    for test_case in test_suite:\n",
    "        test_result = test_runner.run(test_case)\n",
    "        \n",
    "   # Create a Spark session\n",
    "    spark = SparkSession.builder.appName(\"DataQuality\").getOrCreate()\n",
    "    \n",
    "    schema = [\"Table Name\", \"Test Type\", \"Status\", \"Reason\", \"Date\"]\n",
    "    # Converting the test results to spark dataframe\n",
    "    results_df = pd.DataFrame(test_results)\n",
    "    results_df.to_csv(\"DataQuality.csv\", index=False)\n",
    "    # Write the individual Data Quality results to a CSV file\n",
    "    data_quality_df = spark.createDataFrame(results_df, schema=schema) \n",
    "    data_quality_df.show()\n",
    "    \n",
    "     # Create a summary DataFrame to store load status\n",
    "    #load_status_df = data_quality_df.groupby(\"Table Name\")\\\n",
    "     #   .agg(F.max(\"Status\").alias(\"Status\"), F.lit(\"Data Quality Checks\").alias(\"Test Type\"), F.date_sub(F.current_date(), 1).alias(\"Date\"))\n",
    "    load_status_df = data_quality_df.groupby(\"Table Name\")\\\n",
    "        .agg(F.max(\"Status\").alias(\"Status\"), F.lit(\"Data Quality Checks\").alias(\"Test Type\"), F.current_date().alias(\"Date\"))\n",
    "\n",
    "\n",
    "    # Check if any row in the test results DataFrame has \"FAIL\" in the \"Status\" column\n",
    "    if \"FAIL\" in load_status_df.select(\"Status\").distinct().rdd.map(lambda x: x[0].upper()).collect():\n",
    "        # Set the status in the summary DataFrame to \"FAIL\"\n",
    "        load_status_df = load_status_df.withColumn(\"Status\", F.lit(\"FAIL\"))\n",
    "\n",
    "    # Define the file path for the load status CSV\n",
    "    csv_file_path = \"load_status\"\n",
    "    \n",
    "    # Check if the file already exists\n",
    "    #if os.path.isfile(f\"work/digital/logs/{csv_file_path}.csv\"):\n",
    "    if os.path.isfile(f\"{csv_file_path}.csv\"):\n",
    "        print(f\"{csv_file_path}.csv\")\n",
    "        ## Read the existing load status CSV directly\n",
    "        existing_load_status_df = spark.read.csv(f\"{csv_file_path}.csv\", header=True, inferSchema=True)\n",
    "        final_load_status_df = existing_load_status_df.union(load_status_df).distinct()\n",
    "        final_load_status_dfp=final_load_status_df.toPandas()\n",
    "        final_load_status_dfp.to_csv(\"load_status.csv\",index=False)\n",
    "    else:\n",
    "        # The file doesn't exist, create it with the current load status\n",
    "        final_load_status_df = load_status_df\n",
    "        final_load_status_dfp=final_load_status_df.toPandas()\n",
    "        final_load_status_dfp.to_csv(\"load_status.csv\", mode='a', index=False, header=not os.path.exists(\"load_status.csv\"))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed12c22a-134f-4493-ac9e-c8bc07b2ed58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.493s\n",
      "\n",
      "OK\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.205s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------+------+--------------------+--------------------+\n",
      "|        Table Name|          Test Type|Status|              Reason|                Date|\n",
      "+------------------+-------------------+------+--------------------+--------------------+\n",
      "|char_stats_day_dly|test_count_increase|  PASS|Count_increase pe...|2023-09-17 13:04:...|\n",
      "|char_stats_day_dly|   test_primary_key|  FAIL|total of 1 Duplic...|2023-09-17 13:04:...|\n",
      "+------------------+-------------------+------+--------------------+--------------------+\n",
      "\n",
      "Data Quality Job completed successfully\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import yaml\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, upper\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "class TestCharStats(unittest.TestCase):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # Loading configuration from config.yaml\n",
    "        with open(\"config.yaml\", \"r\") as config_file:\n",
    "            config = yaml.safe_load(config_file)\n",
    "\n",
    "        # Create a Spark session\n",
    "        self.spark = SparkSession.builder.appName(\"TestCharStats\").getOrCreate()\n",
    "\n",
    "        # Set the log level to ERROR or FATAL\n",
    "        self.spark.sparkContext.setLogLevel(\"ERROR\")  # You can change \"ERROR\" to \"FATAL\" if needed\n",
    "\n",
    "        # Assign configuration variables\n",
    "        self.table_name = config[\"table_name\"]\n",
    "        self.primary_key_columns = config[\"primary_key_columns\"]\n",
    "        self.threshold_percentage = config[\"threshold_percentage\"]\n",
    "        self.output_path = config[\"output_path\"]\n",
    "        self.log_path = config[\"monitoring_path\"]\n",
    "        self.absolute_table_name =f\"{self.output_path}/{self.table_name}\"\n",
    "        \n",
    "    def log_test_result(self, test_name, status, reason=\"\"):\n",
    "        timestamp = datetime.datetime.now()\n",
    "        # Creating a dictionary for the test result\n",
    "        result = {\n",
    "            \"Table Name\": self.table_name,\n",
    "            \"Test Name\": test_name,\n",
    "            \"Status\": status,\n",
    "            \"Reason\": reason,\n",
    "            \"Timestamp\": timestamp\n",
    "        }\n",
    "        # Append the result to the test_results list\n",
    "        test_results.append(result)\n",
    "\n",
    "    def test_primary_key(self):\n",
    "        # Loading the current data\n",
    "        df = self.spark.read.parquet(self.absolute_table_name)  \n",
    "\n",
    "        # Checking primary key columns to make sure no duplicates\n",
    "        num_rows = df.count()\n",
    "        num_distinct_rows = df.select(*self.primary_key_columns).distinct().count()\n",
    "        if num_rows == num_distinct_rows:\n",
    "            self.log_test_result(\"test_primary_key\", \"PASS\")\n",
    "        else:\n",
    "            count_duplicate_key = num_rows - num_distinct_rows\n",
    "            self.log_test_result(\"test_primary_key\", \"FAIL\", f\"total of {count_duplicate_key} Duplicate primary key values found.\")\n",
    "\n",
    "    def test_count_increase(self):\n",
    "        # Loading the today's and previous day data for the comparision of countyour DataFrames for previous and current loads\n",
    "        df_previous = self.spark.read.parquet(self.absolute_table_name)\n",
    "        df_current = self.spark.read.parquet(self.absolute_table_name)\n",
    "\n",
    "        # Calculating the count of increased percentage\n",
    "        count_previous = df_previous.count()\n",
    "        count_current = df_current.count()\n",
    "        increase_percentage = (count_current - count_previous) / count_previous * 100\n",
    "\n",
    "        if increase_percentage >= self.threshold_percentage:\n",
    "            self.log_test_result(\"test_count_increase\", \"FAIL\", f\"Count_increase percentage is more than threshold\")\n",
    "        else:\n",
    "            self.log_test_result(\"test_count_increase\", \"PASS\", \"Count_increase percentage is below threshold\")\n",
    "            \n",
    "    def daily_log_status(self, results_df):\n",
    "        # Write the individual Data Quality results to a CSV file\n",
    "        results_df.to_csv(f\"{self.log_path}/DataQuality.csv\", index=False)\n",
    "        spark = SparkSession.builder.appName(\"DataQuality\").getOrCreate()\n",
    "        schema = [\"Table Name\", \"Test Type\", \"Status\", \"Reason\", \"Date\"]    \n",
    "        data_quality_df = spark.createDataFrame(results_df, schema=schema) \n",
    "        data_quality_df.show()\n",
    "\n",
    "        # Creating a summary DataFrame to store load status\n",
    "        load_status_df = data_quality_df.groupby(\"Table Name\") \\\n",
    "            .agg(F.max(\"Status\").alias(\"Status\"), F.lit(\"DataQuality\").alias(\"Test Type\"), F.current_date().alias(\"Date\"))\n",
    "\n",
    "        # Checking if any row in the test results DataFrame has \"FAIL\" in the \"Status\" column\n",
    "        if \"FAIL\" in load_status_df.select(\"Status\").distinct().rdd.map(lambda x: x[0].upper()).collect():\n",
    "            # Set the status in the summary DataFrame to \"FAIL\"\n",
    "            load_status_df = load_status_df.withColumn(\"Status\", F.lit(\"FAIL\"))\n",
    "\n",
    "        # Define the file path for the load status CSV\n",
    "        csv_file_path = \"load_status\"\n",
    "\n",
    "        # Check if the log file already exists\n",
    "        if os.path.isfile(f\"{self.log_path}/{csv_file_path}.csv\"):\n",
    "            # Reading the existing load status CSV directly\n",
    "            existing_load_status_df = spark.read.csv(f\"{self.log_path}/{csv_file_path}.csv\", header=True, inferSchema=True)\n",
    "            final_load_status_df = existing_load_status_df.union(load_status_df).distinct()\n",
    "            final_load_status_dfp = final_load_status_df.toPandas()\n",
    "            final_load_status_dfp.to_csv(f\"{self.log_path}/load_status.csv\", index=False)\n",
    "        else:\n",
    "            # if the file doesn't exist, creating it with the current load status\n",
    "            final_load_status_df = load_status_df\n",
    "            final_load_status_dfp = final_load_status_df.toPandas()\n",
    "            final_load_status_dfp.to_csv(f\"{self.log_path}/load_status.csv\", mode='a', index=False, header=not os.path.exists(f\"{self.log_path}/load_status.csv\"))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Creating an empty list to store test results\n",
    "    test_results = []\n",
    "\n",
    "    # Creating a test suite\n",
    "    test_suite = unittest.TestLoader().loadTestsFromTestCase(TestCharStats)\n",
    "\n",
    "    # Running the tests\n",
    "    test_runner = unittest.TextTestRunner()\n",
    "\n",
    "    # Run each test and log the results\n",
    "    for test_case in test_suite:\n",
    "        test_result = test_runner.run(test_case)\n",
    "        \n",
    "     # Converting the test results to write into a file\n",
    "    results_df = pd.DataFrame(test_results)\n",
    "\n",
    "    # Call the daily_log_status function with test_results as an argument\n",
    "    test_instance = TestCharStats()\n",
    "    test_instance.daily_log_status(results_df)\n",
    "    print(\"Data Quality Job completed successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62f88805-d992-4755-9c02-13db8a1309a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.604s\n",
      "\n",
      "OK\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.220s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------+------+---------------------------------------------------+--------------------------+\n",
      "|Table Name        |Test Type          |Status|Reason                                             |Date                      |\n",
      "+------------------+-------------------+------+---------------------------------------------------+--------------------------+\n",
      "|char_stats_day_dly|test_count_increase|PASS  |Count increase percentage  is below threshold (10%)|2023-09-17 14:52:11.975773|\n",
      "|char_stats_day_dly|test_primary_key   |FAIL  |Total of 1 duplicate primary key values found      |2023-09-17 14:52:13.201049|\n",
      "+------------------+-------------------+------+---------------------------------------------------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import yaml\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Function to initialize the logger with the date-appended log file name\n",
    "def init_logger(log_path):\n",
    "    os.makedirs(log_path, exist_ok=True)\n",
    "    log_file_name = f\"DataQuality_{datetime.datetime.now().strftime('%Y%m%d')}.log\"\n",
    "    logging.basicConfig(\n",
    "        filename=os.path.join(log_path, log_file_name),\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "    )\n",
    "\n",
    "class TestCharStats(unittest.TestCase):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # Loading configuration from config.yaml\n",
    "        with open(\"config.yaml\", \"r\") as config_file:\n",
    "            config = yaml.safe_load(config_file)\n",
    "\n",
    "        # Create a Spark session\n",
    "        self.spark = SparkSession.builder.appName(\"TestCharStats\").getOrCreate()\n",
    "\n",
    "        # Set the log level to ERROR or FATAL\n",
    "        self.spark.sparkContext.setLogLevel(\"ERROR\")  # You can change \"ERROR\" to \"FATAL\" if needed\n",
    "\n",
    "        # Assign configuration variables\n",
    "        self.table_name = config[\"table_name\"]\n",
    "        self.primary_key_columns = config[\"primary_key_columns\"]\n",
    "        self.threshold_percentage = config[\"threshold_percentage\"]\n",
    "        self.output_path = config[\"output_path\"]\n",
    "        self.log_path = config[\"monitoring_path\"]\n",
    "        self.logging_path = config[\"log_path\"]\n",
    "        self.absolute_table_name = f\"{self.output_path}/{self.table_name}\"\n",
    "        \n",
    "        # Initialize logger\n",
    "        init_logger(self.logging_path)\n",
    "\n",
    "    # Function to log test results\n",
    "    def log_test_result(self, test_name, status, reason=\"\"):\n",
    "        timestamp = datetime.datetime.now()\n",
    "        # Creating a dictionary for the test result\n",
    "        result = {\n",
    "            \"Table Name\": self.table_name,\n",
    "            \"Test Name\": test_name,\n",
    "            \"Status\": status,\n",
    "            \"Reason\": reason,\n",
    "            \"Timestamp\": timestamp\n",
    "        }\n",
    "        # Append the result to the test_results list\n",
    "        test_results.append(result)\n",
    "\n",
    "    def test_primary_key(self):\n",
    "        try:\n",
    "            # Log the test start\n",
    "            logging.info(\"Starting the process to to test primary_key duplicate check.\")\n",
    "\n",
    "            # Loading the current data\n",
    "            df = self.spark.read.parquet(self.absolute_table_name)\n",
    "            logging.info(f\"Loaded today's data from {self.table_name}.\")\n",
    "\n",
    "            # Checking primary key columns to make sure no duplicates\n",
    "            num_rows = df.count()\n",
    "            num_distinct_rows = df.select(*self.primary_key_columns).distinct().count()\n",
    "            if num_rows == num_distinct_rows:\n",
    "                self.log_test_result(\"test_primary_key\", \"PASS\")\n",
    "                logging.info(\"Duplicate Primary key test passed.\")\n",
    "            else:\n",
    "                count_duplicate_key = num_rows - num_distinct_rows\n",
    "                self.log_test_result(\"test_primary_key\", \"FAIL\", f\"Total of {count_duplicate_key} duplicate primary key values found\")\n",
    "                logging.warning(f\"Primary key test failed: Total of {count_duplicate_key} duplicate primary key values found\")\n",
    "\n",
    "            # Log the test end\n",
    "            logging.info(\"Completed the Primary key duplicate test.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in test_primary_key: {str(e)}\")\n",
    "\n",
    "    def test_count_increase(self):\n",
    "        try:\n",
    "            # Log the test start\n",
    "            logging.info(\"Starting the data quality check to monitor count_increase in today's load.\")\n",
    "\n",
    "            # Loading the today's and previous day data for the comparison of count\n",
    "            df_previous = self.spark.read.parquet(self.absolute_table_name)\n",
    "            df_current = self.spark.read.parquet(self.absolute_table_name)\n",
    "            logging.info(f\"Loaded data from yesterday data from table {self.table_name} for count comparison.\")\n",
    "\n",
    "            # Calculating the count increase percentage\n",
    "            count_previous = df_previous.count()\n",
    "            count_current = df_current.count()\n",
    "            increase_percentage = (count_current - count_previous) / count_previous * 100\n",
    "\n",
    "            if increase_percentage >= self.threshold_percentage:\n",
    "                self.log_test_result(\"test_count_increase\", \"FAIL\", f\"Count increase percentage ({increase_percentage}%) is more than threshold ({self.threshold_percentage}%)\")\n",
    "                logging.warning(f\"Count increase test failed: Count increase percentage ({increase_percentage}%) is more than threshold ({self.threshold_percentage}%)\")\n",
    "            else:\n",
    "                self.log_test_result(\"test_count_increase\", \"PASS\", f\"Count increase percentage  is below threshold ({self.threshold_percentage}%)\")\n",
    "                logging.info(f\"Count increase test passed: Count increase percentage is below threshold ({self.threshold_percentage}%)\")\n",
    "\n",
    "            # Log the test end\n",
    "            logging.info(\"Completed the data check for count_increase in today's load.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in data count_increase process: {str(e)}\")\n",
    "\n",
    "    def daily_log_status(self, results_df):\n",
    "        try:\n",
    "            # Log the daily status start\n",
    "            logging.info(\"Starting the function to log the job satsus in daily_log_status table.\")\n",
    "\n",
    "            # Write the individual Data Quality results to a CSV file\n",
    "            results_df.to_csv(f\"{self.log_path}/DataQuality.csv\", index=False)\n",
    "            logging.info(f\"Saved test results of  DataQuality table.\")\n",
    "\n",
    "            spark = SparkSession.builder.appName(\"DataQuality\").getOrCreate()\n",
    "            schema = [\"Table Name\", \"Test Type\", \"Status\", \"Reason\", \"Date\"]\n",
    "            data_quality_df = spark.createDataFrame(results_df, schema=schema)\n",
    "            data_quality_df.show(truncate=False)\n",
    "            logging.info(\"Displayed Data Quality results.\")\n",
    "\n",
    "            # Creating a summary DataFrame to store load status\n",
    "            load_status_df = data_quality_df.groupby(\"Table Name\") \\\n",
    "                .agg(F.max(\"Status\").alias(\"Status\"), F.lit(\"DataQuality\").alias(\"Test Type\"), F.current_date().alias(\"Date\"))\n",
    "\n",
    "            # Checking if any row in the test results DataFrame has \"FAIL\" in the \"Status\" column\n",
    "            if \"FAIL\" in load_status_df.select(\"Status\").distinct().rdd.map(lambda x: x[0].upper()).collect():\n",
    "                # Set the status in the summary DataFrame to \"FAIL\"\n",
    "                load_status_df = load_status_df.withColumn(\"Status\", F.lit(\"FAIL\"))\n",
    "                logging.warning(\"Load status set to FAIL due to Data Quality test failures.\")\n",
    "            else:\n",
    "                logging.info(\"Load status remains as PASS.\")\n",
    "\n",
    "            # Define the file path for the load status CSV\n",
    "            csv_file_path = \"load_status\"\n",
    "\n",
    "            # Check if the log file already exists\n",
    "            if os.path.isfile(f\"{self.log_path}/{csv_file_path}.csv\"):\n",
    "                # Reading the existing load status CSV directly\n",
    "                existing_load_status_df = spark.read.csv(f\"{self.log_path}/{csv_file_path}.csv\", header=True, inferSchema=True)\n",
    "                final_load_status_df = existing_load_status_df.union(load_status_df).distinct()\n",
    "                final_load_status_dfp = final_load_status_df.toPandas()\n",
    "                final_load_status_dfp.to_csv(f\"{self.log_path}/load_status.csv\", index=False)\n",
    "                logging.info(f\"Appended load status to existing load_status table.\")\n",
    "            else:\n",
    "                # if the file doesn't exist, creating it with the current load status\n",
    "                final_load_status_df = load_status_df\n",
    "                final_load_status_dfp = final_load_status_df.toPandas()\n",
    "                final_load_status_dfp.to_csv(f\"{self.log_path}/load_status.csv\", mode='a', index=False, header=not os.path.exists(f\"{self.log_path}/load_status.csv\"))\n",
    "                logging.info(f\"Created load_status with current load status\")\n",
    "\n",
    "            # Log the daily status end\n",
    "            logging.info(\"Completed the daily_log_status\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in daily_log_status: {str(e)}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Creating an empty list to store test results\n",
    "    test_results = []\n",
    "\n",
    "    # Creating a test suite\n",
    "    test_suite = unittest.TestLoader().loadTestsFromTestCase(TestCharStats)\n",
    "\n",
    "    # Running the tests\n",
    "    test_runner = unittest.TextTestRunner()\n",
    "\n",
    "    # Run each test and log the results\n",
    "    for test_case in test_suite:\n",
    "        test_result = test_runner.run(test_case)\n",
    "        \n",
    "     # Converting the test results to write into a file\n",
    "    results_df = pd.DataFrame(test_results)\n",
    "\n",
    "    # Call the daily_log_status function with test_results as an argument\n",
    "    test_instance = TestCharStats()\n",
    "    test_instance.daily_log_status(results_df)\n",
    "    logging.info(\"Data Quality Job completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec565e84-1335-4455-b05d-030d4abc2489",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
